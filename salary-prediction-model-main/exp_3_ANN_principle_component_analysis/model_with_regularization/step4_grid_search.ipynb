{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e9220b-914d-48fe-b259-58a29bf3ce82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import pandas\n",
    "import warnings\n",
    "import numpy\n",
    "\n",
    "import sklearn.neural_network\n",
    "import sklearn.model_selection\n",
    "import sklearn.exceptions\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0231cf70-47be-4025-819f-699f38c9f4bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principal_feature_1</th>\n",
       "      <th>principal_feature_2</th>\n",
       "      <th>principal_feature_3</th>\n",
       "      <th>principal_feature_4</th>\n",
       "      <th>principal_feature_5</th>\n",
       "      <th>principal_feature_6</th>\n",
       "      <th>principal_feature_7</th>\n",
       "      <th>principal_feature_8</th>\n",
       "      <th>principal_feature_9</th>\n",
       "      <th>principal_feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>principal_feature_22</th>\n",
       "      <th>principal_feature_23</th>\n",
       "      <th>principal_feature_24</th>\n",
       "      <th>principal_feature_25</th>\n",
       "      <th>principal_feature_26</th>\n",
       "      <th>principal_feature_27</th>\n",
       "      <th>principal_feature_28</th>\n",
       "      <th>principal_feature_29</th>\n",
       "      <th>principal_feature_30</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>-4.627833</td>\n",
       "      <td>-0.616020</td>\n",
       "      <td>1.011308</td>\n",
       "      <td>1.157509</td>\n",
       "      <td>-0.969749</td>\n",
       "      <td>0.263241</td>\n",
       "      <td>3.614747</td>\n",
       "      <td>-1.278219</td>\n",
       "      <td>1.025982</td>\n",
       "      <td>-0.205857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037443</td>\n",
       "      <td>-0.181950</td>\n",
       "      <td>-0.087537</td>\n",
       "      <td>-0.069821</td>\n",
       "      <td>-0.123980</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.005652</td>\n",
       "      <td>-0.010169</td>\n",
       "      <td>0.037983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14649</th>\n",
       "      <td>1.426356</td>\n",
       "      <td>-1.070926</td>\n",
       "      <td>-0.445978</td>\n",
       "      <td>-2.012902</td>\n",
       "      <td>-0.774684</td>\n",
       "      <td>-0.178957</td>\n",
       "      <td>-0.175381</td>\n",
       "      <td>0.390812</td>\n",
       "      <td>-0.219342</td>\n",
       "      <td>-0.261077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106603</td>\n",
       "      <td>-0.137346</td>\n",
       "      <td>-0.124422</td>\n",
       "      <td>0.099997</td>\n",
       "      <td>0.049905</td>\n",
       "      <td>-0.067296</td>\n",
       "      <td>0.025073</td>\n",
       "      <td>0.048250</td>\n",
       "      <td>-0.014505</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7379</th>\n",
       "      <td>1.229626</td>\n",
       "      <td>0.949016</td>\n",
       "      <td>-0.062841</td>\n",
       "      <td>-1.722606</td>\n",
       "      <td>-1.057586</td>\n",
       "      <td>0.778410</td>\n",
       "      <td>-0.248871</td>\n",
       "      <td>0.273507</td>\n",
       "      <td>0.549379</td>\n",
       "      <td>1.051496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115777</td>\n",
       "      <td>-0.267204</td>\n",
       "      <td>-0.145887</td>\n",
       "      <td>0.055045</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>-0.048675</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>-0.005442</td>\n",
       "      <td>0.040276</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24479</th>\n",
       "      <td>0.340879</td>\n",
       "      <td>0.772770</td>\n",
       "      <td>-0.966337</td>\n",
       "      <td>-1.342151</td>\n",
       "      <td>-0.797795</td>\n",
       "      <td>0.009330</td>\n",
       "      <td>-0.323072</td>\n",
       "      <td>0.091520</td>\n",
       "      <td>0.804870</td>\n",
       "      <td>0.016989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171550</td>\n",
       "      <td>-0.138507</td>\n",
       "      <td>-0.049719</td>\n",
       "      <td>-0.004557</td>\n",
       "      <td>0.014382</td>\n",
       "      <td>-0.041696</td>\n",
       "      <td>-0.038541</td>\n",
       "      <td>-0.009300</td>\n",
       "      <td>0.079184</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19532</th>\n",
       "      <td>8.454393</td>\n",
       "      <td>0.867535</td>\n",
       "      <td>1.817414</td>\n",
       "      <td>1.123255</td>\n",
       "      <td>0.361935</td>\n",
       "      <td>1.035225</td>\n",
       "      <td>0.181511</td>\n",
       "      <td>0.224099</td>\n",
       "      <td>-0.080475</td>\n",
       "      <td>-0.045255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.648843</td>\n",
       "      <td>0.541824</td>\n",
       "      <td>-0.145423</td>\n",
       "      <td>0.128398</td>\n",
       "      <td>-0.384494</td>\n",
       "      <td>0.034080</td>\n",
       "      <td>-0.421518</td>\n",
       "      <td>0.158369</td>\n",
       "      <td>0.101909</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8695</th>\n",
       "      <td>0.512212</td>\n",
       "      <td>-1.893255</td>\n",
       "      <td>-1.413639</td>\n",
       "      <td>-0.895023</td>\n",
       "      <td>-0.016264</td>\n",
       "      <td>0.180163</td>\n",
       "      <td>-0.074641</td>\n",
       "      <td>-0.896404</td>\n",
       "      <td>0.101968</td>\n",
       "      <td>-0.400639</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.288649</td>\n",
       "      <td>-0.106217</td>\n",
       "      <td>-0.152433</td>\n",
       "      <td>-0.060046</td>\n",
       "      <td>-0.110437</td>\n",
       "      <td>-0.056551</td>\n",
       "      <td>0.009905</td>\n",
       "      <td>0.029002</td>\n",
       "      <td>-0.090838</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>0.239106</td>\n",
       "      <td>0.844269</td>\n",
       "      <td>-0.286306</td>\n",
       "      <td>-1.274410</td>\n",
       "      <td>1.260324</td>\n",
       "      <td>-0.665399</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.114577</td>\n",
       "      <td>0.809178</td>\n",
       "      <td>0.039943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366398</td>\n",
       "      <td>-0.415290</td>\n",
       "      <td>0.758599</td>\n",
       "      <td>-0.127784</td>\n",
       "      <td>-0.054578</td>\n",
       "      <td>-0.312127</td>\n",
       "      <td>-0.002217</td>\n",
       "      <td>-0.006963</td>\n",
       "      <td>0.106812</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8250</th>\n",
       "      <td>1.628326</td>\n",
       "      <td>-2.121414</td>\n",
       "      <td>1.124541</td>\n",
       "      <td>-0.151108</td>\n",
       "      <td>-0.128657</td>\n",
       "      <td>0.072585</td>\n",
       "      <td>-0.063428</td>\n",
       "      <td>-0.335233</td>\n",
       "      <td>0.055916</td>\n",
       "      <td>-0.155903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.414942</td>\n",
       "      <td>-0.074874</td>\n",
       "      <td>-0.270190</td>\n",
       "      <td>-0.033342</td>\n",
       "      <td>-0.304562</td>\n",
       "      <td>0.009105</td>\n",
       "      <td>-0.185370</td>\n",
       "      <td>0.018864</td>\n",
       "      <td>0.067465</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18511</th>\n",
       "      <td>-3.370279</td>\n",
       "      <td>-0.633653</td>\n",
       "      <td>2.278954</td>\n",
       "      <td>2.080791</td>\n",
       "      <td>-0.153023</td>\n",
       "      <td>-1.988961</td>\n",
       "      <td>-0.329479</td>\n",
       "      <td>-0.080015</td>\n",
       "      <td>-0.360904</td>\n",
       "      <td>-0.204693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203309</td>\n",
       "      <td>0.127252</td>\n",
       "      <td>0.264551</td>\n",
       "      <td>-0.026902</td>\n",
       "      <td>0.069529</td>\n",
       "      <td>0.515507</td>\n",
       "      <td>0.215882</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>-0.661055</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16074</th>\n",
       "      <td>2.293897</td>\n",
       "      <td>0.898854</td>\n",
       "      <td>-0.679156</td>\n",
       "      <td>-1.310976</td>\n",
       "      <td>-0.685169</td>\n",
       "      <td>0.143758</td>\n",
       "      <td>-0.203819</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>0.647041</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212200</td>\n",
       "      <td>-0.357577</td>\n",
       "      <td>-0.030663</td>\n",
       "      <td>0.080671</td>\n",
       "      <td>-0.078369</td>\n",
       "      <td>-0.079230</td>\n",
       "      <td>0.504632</td>\n",
       "      <td>-0.194059</td>\n",
       "      <td>0.060216</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15675 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       principal_feature_1  principal_feature_2  principal_feature_3  \\\n",
       "id                                                                     \n",
       "2103             -4.627833            -0.616020             1.011308   \n",
       "14649             1.426356            -1.070926            -0.445978   \n",
       "7379              1.229626             0.949016            -0.062841   \n",
       "24479             0.340879             0.772770            -0.966337   \n",
       "19532             8.454393             0.867535             1.817414   \n",
       "...                    ...                  ...                  ...   \n",
       "8695              0.512212            -1.893255            -1.413639   \n",
       "2192              0.239106             0.844269            -0.286306   \n",
       "8250              1.628326            -2.121414             1.124541   \n",
       "18511            -3.370279            -0.633653             2.278954   \n",
       "16074             2.293897             0.898854            -0.679156   \n",
       "\n",
       "       principal_feature_4  principal_feature_5  principal_feature_6  \\\n",
       "id                                                                     \n",
       "2103              1.157509            -0.969749             0.263241   \n",
       "14649            -2.012902            -0.774684            -0.178957   \n",
       "7379             -1.722606            -1.057586             0.778410   \n",
       "24479            -1.342151            -0.797795             0.009330   \n",
       "19532             1.123255             0.361935             1.035225   \n",
       "...                    ...                  ...                  ...   \n",
       "8695             -0.895023            -0.016264             0.180163   \n",
       "2192             -1.274410             1.260324            -0.665399   \n",
       "8250             -0.151108            -0.128657             0.072585   \n",
       "18511             2.080791            -0.153023            -1.988961   \n",
       "16074            -1.310976            -0.685169             0.143758   \n",
       "\n",
       "       principal_feature_7  principal_feature_8  principal_feature_9  \\\n",
       "id                                                                     \n",
       "2103              3.614747            -1.278219             1.025982   \n",
       "14649            -0.175381             0.390812            -0.219342   \n",
       "7379             -0.248871             0.273507             0.549379   \n",
       "24479            -0.323072             0.091520             0.804870   \n",
       "19532             0.181511             0.224099            -0.080475   \n",
       "...                    ...                  ...                  ...   \n",
       "8695             -0.074641            -0.896404             0.101968   \n",
       "2192              0.003516             0.114577             0.809178   \n",
       "8250             -0.063428            -0.335233             0.055916   \n",
       "18511            -0.329479            -0.080015            -0.360904   \n",
       "16074            -0.203819             0.297000             0.647041   \n",
       "\n",
       "       principal_feature_10  ...  principal_feature_22  principal_feature_23  \\\n",
       "id                           ...                                               \n",
       "2103              -0.205857  ...              0.037443             -0.181950   \n",
       "14649             -0.261077  ...             -0.106603             -0.137346   \n",
       "7379               1.051496  ...              0.115777             -0.267204   \n",
       "24479              0.016989  ...              0.171550             -0.138507   \n",
       "19532             -0.045255  ...              0.648843              0.541824   \n",
       "...                     ...  ...                   ...                   ...   \n",
       "8695              -0.400639  ...             -0.288649             -0.106217   \n",
       "2192               0.039943  ...              0.366398             -0.415290   \n",
       "8250              -0.155903  ...             -0.414942             -0.074874   \n",
       "18511             -0.204693  ...              0.203309              0.127252   \n",
       "16074              0.917722  ...              0.212200             -0.357577   \n",
       "\n",
       "       principal_feature_24  principal_feature_25  principal_feature_26  \\\n",
       "id                                                                        \n",
       "2103              -0.087537             -0.069821             -0.123980   \n",
       "14649             -0.124422              0.099997              0.049905   \n",
       "7379              -0.145887              0.055045              0.000938   \n",
       "24479             -0.049719             -0.004557              0.014382   \n",
       "19532             -0.145423              0.128398             -0.384494   \n",
       "...                     ...                   ...                   ...   \n",
       "8695              -0.152433             -0.060046             -0.110437   \n",
       "2192               0.758599             -0.127784             -0.054578   \n",
       "8250              -0.270190             -0.033342             -0.304562   \n",
       "18511              0.264551             -0.026902              0.069529   \n",
       "16074             -0.030663              0.080671             -0.078369   \n",
       "\n",
       "       principal_feature_27  principal_feature_28  principal_feature_29  \\\n",
       "id                                                                        \n",
       "2103              -0.054105             -0.005652             -0.010169   \n",
       "14649             -0.067296              0.025073              0.048250   \n",
       "7379              -0.048675              0.003114             -0.005442   \n",
       "24479             -0.041696             -0.038541             -0.009300   \n",
       "19532              0.034080             -0.421518              0.158369   \n",
       "...                     ...                   ...                   ...   \n",
       "8695              -0.056551              0.009905              0.029002   \n",
       "2192              -0.312127             -0.002217             -0.006963   \n",
       "8250               0.009105             -0.185370              0.018864   \n",
       "18511              0.515507              0.215882              0.028169   \n",
       "16074             -0.079230              0.504632             -0.194059   \n",
       "\n",
       "       principal_feature_30  label  \n",
       "id                                  \n",
       "2103               0.037983    1.0  \n",
       "14649             -0.014505    0.0  \n",
       "7379               0.040276    0.0  \n",
       "24479              0.079184    0.0  \n",
       "19532              0.101909    0.0  \n",
       "...                     ...    ...  \n",
       "8695              -0.090838    0.0  \n",
       "2192               0.106812    0.0  \n",
       "8250               0.067465    0.0  \n",
       "18511             -0.661055    1.0  \n",
       "16074              0.060216    0.0  \n",
       "\n",
       "[15675 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pandas.read_csv('../data/features.train.csv').set_index('id')\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0117fbb4-366b-4035-b439-132a1e67aaab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = sklearn.neural_network.MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 10),\n",
    "    solver='sgd', \n",
    "    activation='logistic',\n",
    "    alpha=0.0,  \n",
    "    batch_size=32,\n",
    "    learning_rate='constant',\n",
    "    learning_rate_init=0.1,\n",
    "    max_iter=1000,\n",
    "    momentum=0.0, \n",
    "    nesterovs_momentum=False, \n",
    "    validation_fraction=0.0,\n",
    "    shuffle=True,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8848b245-00d9-4b59-ad35-851f9669b476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_parameters = {\n",
    "    'alpha': [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa989814-ca7c-4bc2-a785-fdca974f33fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = sklearn.model_selection.GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=search_parameters,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1fd4ce8-c417-4e62-bb5d-ef579e9dc9f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=MLPClassifier(activation=&#x27;logistic&#x27;, alpha=0.0,\n",
       "                                     batch_size=32, hidden_layer_sizes=(20, 10),\n",
       "                                     learning_rate_init=0.1, max_iter=1000,\n",
       "                                     momentum=0.0, nesterovs_momentum=False,\n",
       "                                     random_state=0, solver=&#x27;sgd&#x27;,\n",
       "                                     validation_fraction=0.0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.001, 0.002, 0.003, 0.004, 0.005, 0.006,\n",
       "                                   0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04,\n",
       "                                   0.05, 0.06, 0.07, 0.08, 0.09, 0.1]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=MLPClassifier(activation=&#x27;logistic&#x27;, alpha=0.0,\n",
       "                                     batch_size=32, hidden_layer_sizes=(20, 10),\n",
       "                                     learning_rate_init=0.1, max_iter=1000,\n",
       "                                     momentum=0.0, nesterovs_momentum=False,\n",
       "                                     random_state=0, solver=&#x27;sgd&#x27;,\n",
       "                                     validation_fraction=0.0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.001, 0.002, 0.003, 0.004, 0.005, 0.006,\n",
       "                                   0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04,\n",
       "                                   0.05, 0.06, 0.07, 0.08, 0.09, 0.1]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=0.0, batch_size=32,\n",
       "              hidden_layer_sizes=(20, 10), learning_rate_init=0.1,\n",
       "              max_iter=1000, momentum=0.0, nesterovs_momentum=False,\n",
       "              random_state=0, solver=&#x27;sgd&#x27;, validation_fraction=0.0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=0.0, batch_size=32,\n",
       "              hidden_layer_sizes=(20, 10), learning_rate_init=0.1,\n",
       "              max_iter=1000, momentum=0.0, nesterovs_momentum=False,\n",
       "              random_state=0, solver=&#x27;sgd&#x27;, validation_fraction=0.0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=MLPClassifier(activation='logistic', alpha=0.0,\n",
       "                                     batch_size=32, hidden_layer_sizes=(20, 10),\n",
       "                                     learning_rate_init=0.1, max_iter=1000,\n",
       "                                     momentum=0.0, nesterovs_momentum=False,\n",
       "                                     random_state=0, solver='sgd',\n",
       "                                     validation_fraction=0.0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'alpha': [0.001, 0.002, 0.003, 0.004, 0.005, 0.006,\n",
       "                                   0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04,\n",
       "                                   0.05, 0.06, 0.07, 0.08, 0.09, 0.1]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.fit(\n",
    "    data_train.drop(['label'], axis='columns'),\n",
    "    data_train['label'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "637722a4-7955-42f8-9033-b0ad764d87b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.278852</td>\n",
       "      <td>9.462776</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.825199</td>\n",
       "      <td>0.820415</td>\n",
       "      <td>0.825199</td>\n",
       "      <td>0.825199</td>\n",
       "      <td>0.821308</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.683776</td>\n",
       "      <td>10.730268</td>\n",
       "      <td>0.006117</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.002</td>\n",
       "      <td>{'alpha': 0.002}</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.825199</td>\n",
       "      <td>0.819458</td>\n",
       "      <td>0.820415</td>\n",
       "      <td>0.822967</td>\n",
       "      <td>0.819713</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.626942</td>\n",
       "      <td>9.400198</td>\n",
       "      <td>0.005812</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'alpha': 0.003}</td>\n",
       "      <td>0.809250</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.818820</td>\n",
       "      <td>0.820096</td>\n",
       "      <td>0.822967</td>\n",
       "      <td>0.819139</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.812677</td>\n",
       "      <td>5.091564</td>\n",
       "      <td>0.006704</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.004</td>\n",
       "      <td>{'alpha': 0.004}</td>\n",
       "      <td>0.809250</td>\n",
       "      <td>0.823923</td>\n",
       "      <td>0.817544</td>\n",
       "      <td>0.820096</td>\n",
       "      <td>0.818501</td>\n",
       "      <td>0.817863</td>\n",
       "      <td>0.004825</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.646162</td>\n",
       "      <td>4.108666</td>\n",
       "      <td>0.007011</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'alpha': 0.005}</td>\n",
       "      <td>0.815949</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.820096</td>\n",
       "      <td>0.820096</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.819777</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.706174</td>\n",
       "      <td>4.545652</td>\n",
       "      <td>0.007160</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'alpha': 0.006}</td>\n",
       "      <td>0.815311</td>\n",
       "      <td>0.824880</td>\n",
       "      <td>0.819777</td>\n",
       "      <td>0.821691</td>\n",
       "      <td>0.816906</td>\n",
       "      <td>0.819713</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22.366439</td>\n",
       "      <td>0.573180</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.007</td>\n",
       "      <td>{'alpha': 0.007}</td>\n",
       "      <td>0.814992</td>\n",
       "      <td>0.823285</td>\n",
       "      <td>0.823285</td>\n",
       "      <td>0.816906</td>\n",
       "      <td>0.815949</td>\n",
       "      <td>0.818884</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.740125</td>\n",
       "      <td>1.097402</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.008</td>\n",
       "      <td>{'alpha': 0.008}</td>\n",
       "      <td>0.814354</td>\n",
       "      <td>0.822329</td>\n",
       "      <td>0.823604</td>\n",
       "      <td>0.817544</td>\n",
       "      <td>0.815311</td>\n",
       "      <td>0.818628</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.371558</td>\n",
       "      <td>0.697355</td>\n",
       "      <td>0.006839</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.009</td>\n",
       "      <td>{'alpha': 0.009}</td>\n",
       "      <td>0.814354</td>\n",
       "      <td>0.822648</td>\n",
       "      <td>0.825199</td>\n",
       "      <td>0.817863</td>\n",
       "      <td>0.814673</td>\n",
       "      <td>0.818947</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.425578</td>\n",
       "      <td>0.765435</td>\n",
       "      <td>0.006922</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.813716</td>\n",
       "      <td>0.822967</td>\n",
       "      <td>0.824880</td>\n",
       "      <td>0.817544</td>\n",
       "      <td>0.813716</td>\n",
       "      <td>0.818565</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22.346226</td>\n",
       "      <td>0.820641</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'alpha': 0.02}</td>\n",
       "      <td>0.815311</td>\n",
       "      <td>0.824242</td>\n",
       "      <td>0.824880</td>\n",
       "      <td>0.821372</td>\n",
       "      <td>0.812121</td>\n",
       "      <td>0.819585</td>\n",
       "      <td>0.005038</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20.762869</td>\n",
       "      <td>2.637624</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'alpha': 0.03}</td>\n",
       "      <td>0.817863</td>\n",
       "      <td>0.825518</td>\n",
       "      <td>0.814035</td>\n",
       "      <td>0.821372</td>\n",
       "      <td>0.814035</td>\n",
       "      <td>0.818565</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18.510338</td>\n",
       "      <td>4.693114</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.04</td>\n",
       "      <td>{'alpha': 0.04}</td>\n",
       "      <td>0.817544</td>\n",
       "      <td>0.826794</td>\n",
       "      <td>0.812440</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.812440</td>\n",
       "      <td>0.818054</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17.156269</td>\n",
       "      <td>3.959633</td>\n",
       "      <td>0.006806</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'alpha': 0.05}</td>\n",
       "      <td>0.807656</td>\n",
       "      <td>0.825837</td>\n",
       "      <td>0.809250</td>\n",
       "      <td>0.819139</td>\n",
       "      <td>0.811802</td>\n",
       "      <td>0.814737</td>\n",
       "      <td>0.006804</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17.443509</td>\n",
       "      <td>3.697879</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.06</td>\n",
       "      <td>{'alpha': 0.06}</td>\n",
       "      <td>0.808293</td>\n",
       "      <td>0.825837</td>\n",
       "      <td>0.807974</td>\n",
       "      <td>0.817225</td>\n",
       "      <td>0.811802</td>\n",
       "      <td>0.814226</td>\n",
       "      <td>0.006693</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.377057</td>\n",
       "      <td>4.175382</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.07</td>\n",
       "      <td>{'alpha': 0.07}</td>\n",
       "      <td>0.808612</td>\n",
       "      <td>0.825199</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>0.817225</td>\n",
       "      <td>0.811483</td>\n",
       "      <td>0.813716</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15.061616</td>\n",
       "      <td>4.316649</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.08</td>\n",
       "      <td>{'alpha': 0.08}</td>\n",
       "      <td>0.807656</td>\n",
       "      <td>0.826156</td>\n",
       "      <td>0.808612</td>\n",
       "      <td>0.814992</td>\n",
       "      <td>0.811164</td>\n",
       "      <td>0.813716</td>\n",
       "      <td>0.006718</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14.145695</td>\n",
       "      <td>2.922736</td>\n",
       "      <td>0.006518</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.09</td>\n",
       "      <td>{'alpha': 0.09}</td>\n",
       "      <td>0.806699</td>\n",
       "      <td>0.827432</td>\n",
       "      <td>0.807974</td>\n",
       "      <td>0.814035</td>\n",
       "      <td>0.811164</td>\n",
       "      <td>0.813461</td>\n",
       "      <td>0.007438</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12.100322</td>\n",
       "      <td>2.349949</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>0.827113</td>\n",
       "      <td>0.805423</td>\n",
       "      <td>0.814035</td>\n",
       "      <td>0.813078</td>\n",
       "      <td>0.813142</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       43.278852      9.462776         0.006482        0.000539       0.001   \n",
       "1       33.683776     10.730268         0.006117        0.000543       0.002   \n",
       "2       28.626942      9.400198         0.005812        0.000595       0.003   \n",
       "3       23.812677      5.091564         0.006704        0.000454       0.004   \n",
       "4       24.646162      4.108666         0.007011        0.000074       0.005   \n",
       "5       25.706174      4.545652         0.007160        0.000335       0.006   \n",
       "6       22.366439      0.573180         0.008521        0.001945       0.007   \n",
       "7       22.740125      1.097402         0.007141        0.000653       0.008   \n",
       "8       22.371558      0.697355         0.006839        0.000197       0.009   \n",
       "9       22.425578      0.765435         0.006922        0.000227        0.01   \n",
       "10      22.346226      0.820641         0.006763        0.000125        0.02   \n",
       "11      20.762869      2.637624         0.006763        0.000122        0.03   \n",
       "12      18.510338      4.693114         0.006798        0.000108        0.04   \n",
       "13      17.156269      3.959633         0.006806        0.000351        0.05   \n",
       "14      17.443509      3.697879         0.006988        0.000314        0.06   \n",
       "15      16.377057      4.175382         0.006982        0.000464        0.07   \n",
       "16      15.061616      4.316649         0.007144        0.000337        0.08   \n",
       "17      14.145695      2.922736         0.006518        0.002040        0.09   \n",
       "18      12.100322      2.349949         0.003982        0.001209         0.1   \n",
       "\n",
       "              params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0   {'alpha': 0.001}           0.810526           0.825199           0.820415   \n",
       "1   {'alpha': 0.002}           0.810526           0.825199           0.819458   \n",
       "2   {'alpha': 0.003}           0.809250           0.824561           0.818820   \n",
       "3   {'alpha': 0.004}           0.809250           0.823923           0.817544   \n",
       "4   {'alpha': 0.005}           0.815949           0.824561           0.820096   \n",
       "5   {'alpha': 0.006}           0.815311           0.824880           0.819777   \n",
       "6   {'alpha': 0.007}           0.814992           0.823285           0.823285   \n",
       "7   {'alpha': 0.008}           0.814354           0.822329           0.823604   \n",
       "8   {'alpha': 0.009}           0.814354           0.822648           0.825199   \n",
       "9    {'alpha': 0.01}           0.813716           0.822967           0.824880   \n",
       "10   {'alpha': 0.02}           0.815311           0.824242           0.824880   \n",
       "11   {'alpha': 0.03}           0.817863           0.825518           0.814035   \n",
       "12   {'alpha': 0.04}           0.817544           0.826794           0.812440   \n",
       "13   {'alpha': 0.05}           0.807656           0.825837           0.809250   \n",
       "14   {'alpha': 0.06}           0.808293           0.825837           0.807974   \n",
       "15   {'alpha': 0.07}           0.808612           0.825199           0.806061   \n",
       "16   {'alpha': 0.08}           0.807656           0.826156           0.808612   \n",
       "17   {'alpha': 0.09}           0.806699           0.827432           0.807974   \n",
       "18    {'alpha': 0.1}           0.806061           0.827113           0.805423   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.825199           0.825199         0.821308        0.005700   \n",
       "1            0.820415           0.822967         0.819713        0.005013   \n",
       "2            0.820096           0.822967         0.819139        0.005345   \n",
       "3            0.820096           0.818501         0.817863        0.004825   \n",
       "4            0.820096           0.818182         0.819777        0.002839   \n",
       "5            0.821691           0.816906         0.819713        0.003402   \n",
       "6            0.816906           0.815949         0.818884        0.003645   \n",
       "7            0.817544           0.815311         0.818628        0.003712   \n",
       "8            0.817863           0.814673         0.818947        0.004320   \n",
       "9            0.817544           0.813716         0.818565        0.004633   \n",
       "10           0.821372           0.812121         0.819585        0.005038   \n",
       "11           0.821372           0.814035         0.818565        0.004422   \n",
       "12           0.821053           0.812440         0.818054        0.005453   \n",
       "13           0.819139           0.811802         0.814737        0.006804   \n",
       "14           0.817225           0.811802         0.814226        0.006693   \n",
       "15           0.817225           0.811483         0.813716        0.006838   \n",
       "16           0.814992           0.811164         0.813716        0.006718   \n",
       "17           0.814035           0.811164         0.813461        0.007438   \n",
       "18           0.814035           0.813078         0.813142        0.007820   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                 4  \n",
       "2                 6  \n",
       "3                13  \n",
       "4                 2  \n",
       "5                 3  \n",
       "6                 8  \n",
       "7                 9  \n",
       "8                 7  \n",
       "9                10  \n",
       "10                5  \n",
       "11               10  \n",
       "12               12  \n",
       "13               14  \n",
       "14               15  \n",
       "15               16  \n",
       "16               16  \n",
       "17               18  \n",
       "18               19  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pandas.DataFrame(optimizer.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edb9761d-468c-48f8-9e49-74a17a5c4b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.278852</td>\n",
       "      <td>9.462776</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.825199</td>\n",
       "      <td>0.820415</td>\n",
       "      <td>0.825199</td>\n",
       "      <td>0.825199</td>\n",
       "      <td>0.821308</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.646162</td>\n",
       "      <td>4.108666</td>\n",
       "      <td>0.007011</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'alpha': 0.005}</td>\n",
       "      <td>0.815949</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.820096</td>\n",
       "      <td>0.820096</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.819777</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.706174</td>\n",
       "      <td>4.545652</td>\n",
       "      <td>0.007160</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'alpha': 0.006}</td>\n",
       "      <td>0.815311</td>\n",
       "      <td>0.824880</td>\n",
       "      <td>0.819777</td>\n",
       "      <td>0.821691</td>\n",
       "      <td>0.816906</td>\n",
       "      <td>0.819713</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.683776</td>\n",
       "      <td>10.730268</td>\n",
       "      <td>0.006117</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.002</td>\n",
       "      <td>{'alpha': 0.002}</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.825199</td>\n",
       "      <td>0.819458</td>\n",
       "      <td>0.820415</td>\n",
       "      <td>0.822967</td>\n",
       "      <td>0.819713</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22.346226</td>\n",
       "      <td>0.820641</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'alpha': 0.02}</td>\n",
       "      <td>0.815311</td>\n",
       "      <td>0.824242</td>\n",
       "      <td>0.824880</td>\n",
       "      <td>0.821372</td>\n",
       "      <td>0.812121</td>\n",
       "      <td>0.819585</td>\n",
       "      <td>0.005038</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.626942</td>\n",
       "      <td>9.400198</td>\n",
       "      <td>0.005812</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'alpha': 0.003}</td>\n",
       "      <td>0.809250</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.818820</td>\n",
       "      <td>0.820096</td>\n",
       "      <td>0.822967</td>\n",
       "      <td>0.819139</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.371558</td>\n",
       "      <td>0.697355</td>\n",
       "      <td>0.006839</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.009</td>\n",
       "      <td>{'alpha': 0.009}</td>\n",
       "      <td>0.814354</td>\n",
       "      <td>0.822648</td>\n",
       "      <td>0.825199</td>\n",
       "      <td>0.817863</td>\n",
       "      <td>0.814673</td>\n",
       "      <td>0.818947</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22.366439</td>\n",
       "      <td>0.573180</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.007</td>\n",
       "      <td>{'alpha': 0.007}</td>\n",
       "      <td>0.814992</td>\n",
       "      <td>0.823285</td>\n",
       "      <td>0.823285</td>\n",
       "      <td>0.816906</td>\n",
       "      <td>0.815949</td>\n",
       "      <td>0.818884</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.740125</td>\n",
       "      <td>1.097402</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.008</td>\n",
       "      <td>{'alpha': 0.008}</td>\n",
       "      <td>0.814354</td>\n",
       "      <td>0.822329</td>\n",
       "      <td>0.823604</td>\n",
       "      <td>0.817544</td>\n",
       "      <td>0.815311</td>\n",
       "      <td>0.818628</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20.762869</td>\n",
       "      <td>2.637624</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'alpha': 0.03}</td>\n",
       "      <td>0.817863</td>\n",
       "      <td>0.825518</td>\n",
       "      <td>0.814035</td>\n",
       "      <td>0.821372</td>\n",
       "      <td>0.814035</td>\n",
       "      <td>0.818565</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.425578</td>\n",
       "      <td>0.765435</td>\n",
       "      <td>0.006922</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.813716</td>\n",
       "      <td>0.822967</td>\n",
       "      <td>0.824880</td>\n",
       "      <td>0.817544</td>\n",
       "      <td>0.813716</td>\n",
       "      <td>0.818565</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18.510338</td>\n",
       "      <td>4.693114</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.04</td>\n",
       "      <td>{'alpha': 0.04}</td>\n",
       "      <td>0.817544</td>\n",
       "      <td>0.826794</td>\n",
       "      <td>0.812440</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.812440</td>\n",
       "      <td>0.818054</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.812677</td>\n",
       "      <td>5.091564</td>\n",
       "      <td>0.006704</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.004</td>\n",
       "      <td>{'alpha': 0.004}</td>\n",
       "      <td>0.809250</td>\n",
       "      <td>0.823923</td>\n",
       "      <td>0.817544</td>\n",
       "      <td>0.820096</td>\n",
       "      <td>0.818501</td>\n",
       "      <td>0.817863</td>\n",
       "      <td>0.004825</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17.156269</td>\n",
       "      <td>3.959633</td>\n",
       "      <td>0.006806</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'alpha': 0.05}</td>\n",
       "      <td>0.807656</td>\n",
       "      <td>0.825837</td>\n",
       "      <td>0.809250</td>\n",
       "      <td>0.819139</td>\n",
       "      <td>0.811802</td>\n",
       "      <td>0.814737</td>\n",
       "      <td>0.006804</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17.443509</td>\n",
       "      <td>3.697879</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.06</td>\n",
       "      <td>{'alpha': 0.06}</td>\n",
       "      <td>0.808293</td>\n",
       "      <td>0.825837</td>\n",
       "      <td>0.807974</td>\n",
       "      <td>0.817225</td>\n",
       "      <td>0.811802</td>\n",
       "      <td>0.814226</td>\n",
       "      <td>0.006693</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.377057</td>\n",
       "      <td>4.175382</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.07</td>\n",
       "      <td>{'alpha': 0.07}</td>\n",
       "      <td>0.808612</td>\n",
       "      <td>0.825199</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>0.817225</td>\n",
       "      <td>0.811483</td>\n",
       "      <td>0.813716</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15.061616</td>\n",
       "      <td>4.316649</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.08</td>\n",
       "      <td>{'alpha': 0.08}</td>\n",
       "      <td>0.807656</td>\n",
       "      <td>0.826156</td>\n",
       "      <td>0.808612</td>\n",
       "      <td>0.814992</td>\n",
       "      <td>0.811164</td>\n",
       "      <td>0.813716</td>\n",
       "      <td>0.006718</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14.145695</td>\n",
       "      <td>2.922736</td>\n",
       "      <td>0.006518</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.09</td>\n",
       "      <td>{'alpha': 0.09}</td>\n",
       "      <td>0.806699</td>\n",
       "      <td>0.827432</td>\n",
       "      <td>0.807974</td>\n",
       "      <td>0.814035</td>\n",
       "      <td>0.811164</td>\n",
       "      <td>0.813461</td>\n",
       "      <td>0.007438</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12.100322</td>\n",
       "      <td>2.349949</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.806061</td>\n",
       "      <td>0.827113</td>\n",
       "      <td>0.805423</td>\n",
       "      <td>0.814035</td>\n",
       "      <td>0.813078</td>\n",
       "      <td>0.813142</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       43.278852      9.462776         0.006482        0.000539       0.001   \n",
       "4       24.646162      4.108666         0.007011        0.000074       0.005   \n",
       "5       25.706174      4.545652         0.007160        0.000335       0.006   \n",
       "1       33.683776     10.730268         0.006117        0.000543       0.002   \n",
       "10      22.346226      0.820641         0.006763        0.000125        0.02   \n",
       "2       28.626942      9.400198         0.005812        0.000595       0.003   \n",
       "8       22.371558      0.697355         0.006839        0.000197       0.009   \n",
       "6       22.366439      0.573180         0.008521        0.001945       0.007   \n",
       "7       22.740125      1.097402         0.007141        0.000653       0.008   \n",
       "11      20.762869      2.637624         0.006763        0.000122        0.03   \n",
       "9       22.425578      0.765435         0.006922        0.000227        0.01   \n",
       "12      18.510338      4.693114         0.006798        0.000108        0.04   \n",
       "3       23.812677      5.091564         0.006704        0.000454       0.004   \n",
       "13      17.156269      3.959633         0.006806        0.000351        0.05   \n",
       "14      17.443509      3.697879         0.006988        0.000314        0.06   \n",
       "15      16.377057      4.175382         0.006982        0.000464        0.07   \n",
       "16      15.061616      4.316649         0.007144        0.000337        0.08   \n",
       "17      14.145695      2.922736         0.006518        0.002040        0.09   \n",
       "18      12.100322      2.349949         0.003982        0.001209         0.1   \n",
       "\n",
       "              params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0   {'alpha': 0.001}           0.810526           0.825199           0.820415   \n",
       "4   {'alpha': 0.005}           0.815949           0.824561           0.820096   \n",
       "5   {'alpha': 0.006}           0.815311           0.824880           0.819777   \n",
       "1   {'alpha': 0.002}           0.810526           0.825199           0.819458   \n",
       "10   {'alpha': 0.02}           0.815311           0.824242           0.824880   \n",
       "2   {'alpha': 0.003}           0.809250           0.824561           0.818820   \n",
       "8   {'alpha': 0.009}           0.814354           0.822648           0.825199   \n",
       "6   {'alpha': 0.007}           0.814992           0.823285           0.823285   \n",
       "7   {'alpha': 0.008}           0.814354           0.822329           0.823604   \n",
       "11   {'alpha': 0.03}           0.817863           0.825518           0.814035   \n",
       "9    {'alpha': 0.01}           0.813716           0.822967           0.824880   \n",
       "12   {'alpha': 0.04}           0.817544           0.826794           0.812440   \n",
       "3   {'alpha': 0.004}           0.809250           0.823923           0.817544   \n",
       "13   {'alpha': 0.05}           0.807656           0.825837           0.809250   \n",
       "14   {'alpha': 0.06}           0.808293           0.825837           0.807974   \n",
       "15   {'alpha': 0.07}           0.808612           0.825199           0.806061   \n",
       "16   {'alpha': 0.08}           0.807656           0.826156           0.808612   \n",
       "17   {'alpha': 0.09}           0.806699           0.827432           0.807974   \n",
       "18    {'alpha': 0.1}           0.806061           0.827113           0.805423   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.825199           0.825199         0.821308        0.005700   \n",
       "4            0.820096           0.818182         0.819777        0.002839   \n",
       "5            0.821691           0.816906         0.819713        0.003402   \n",
       "1            0.820415           0.822967         0.819713        0.005013   \n",
       "10           0.821372           0.812121         0.819585        0.005038   \n",
       "2            0.820096           0.822967         0.819139        0.005345   \n",
       "8            0.817863           0.814673         0.818947        0.004320   \n",
       "6            0.816906           0.815949         0.818884        0.003645   \n",
       "7            0.817544           0.815311         0.818628        0.003712   \n",
       "11           0.821372           0.814035         0.818565        0.004422   \n",
       "9            0.817544           0.813716         0.818565        0.004633   \n",
       "12           0.821053           0.812440         0.818054        0.005453   \n",
       "3            0.820096           0.818501         0.817863        0.004825   \n",
       "13           0.819139           0.811802         0.814737        0.006804   \n",
       "14           0.817225           0.811802         0.814226        0.006693   \n",
       "15           0.817225           0.811483         0.813716        0.006838   \n",
       "16           0.814992           0.811164         0.813716        0.006718   \n",
       "17           0.814035           0.811164         0.813461        0.007438   \n",
       "18           0.814035           0.813078         0.813142        0.007820   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "4                 2  \n",
       "5                 3  \n",
       "1                 4  \n",
       "10                5  \n",
       "2                 6  \n",
       "8                 7  \n",
       "6                 8  \n",
       "7                 9  \n",
       "11               10  \n",
       "9                10  \n",
       "12               12  \n",
       "3                13  \n",
       "13               14  \n",
       "14               15  \n",
       "15               16  \n",
       "16               16  \n",
       "17               18  \n",
       "18               19  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.sort_values(['rank_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb856a7a-1fbe-45b5-b904-729b81020dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
