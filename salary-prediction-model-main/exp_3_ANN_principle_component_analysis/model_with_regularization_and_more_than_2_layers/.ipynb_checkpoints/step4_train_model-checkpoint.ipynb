{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33c5fe5-ff8e-4223-b118-cdaf64ca1726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import pandas\n",
    "\n",
    "import sklearn.neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4f449bd-822d-4074-860e-446faf6949ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principal_feature_1</th>\n",
       "      <th>principal_feature_2</th>\n",
       "      <th>principal_feature_3</th>\n",
       "      <th>principal_feature_4</th>\n",
       "      <th>principal_feature_5</th>\n",
       "      <th>principal_feature_6</th>\n",
       "      <th>principal_feature_7</th>\n",
       "      <th>principal_feature_8</th>\n",
       "      <th>principal_feature_9</th>\n",
       "      <th>principal_feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>principal_feature_22</th>\n",
       "      <th>principal_feature_23</th>\n",
       "      <th>principal_feature_24</th>\n",
       "      <th>principal_feature_25</th>\n",
       "      <th>principal_feature_26</th>\n",
       "      <th>principal_feature_27</th>\n",
       "      <th>principal_feature_28</th>\n",
       "      <th>principal_feature_29</th>\n",
       "      <th>principal_feature_30</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>-4.627833</td>\n",
       "      <td>-0.616020</td>\n",
       "      <td>1.011308</td>\n",
       "      <td>1.157509</td>\n",
       "      <td>-0.969749</td>\n",
       "      <td>0.263241</td>\n",
       "      <td>3.614747</td>\n",
       "      <td>-1.278219</td>\n",
       "      <td>1.025982</td>\n",
       "      <td>-0.205857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037443</td>\n",
       "      <td>-0.181950</td>\n",
       "      <td>-0.087537</td>\n",
       "      <td>-0.069821</td>\n",
       "      <td>-0.123980</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>-0.005652</td>\n",
       "      <td>-0.010169</td>\n",
       "      <td>0.037983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14649</th>\n",
       "      <td>1.426356</td>\n",
       "      <td>-1.070926</td>\n",
       "      <td>-0.445978</td>\n",
       "      <td>-2.012902</td>\n",
       "      <td>-0.774684</td>\n",
       "      <td>-0.178957</td>\n",
       "      <td>-0.175381</td>\n",
       "      <td>0.390812</td>\n",
       "      <td>-0.219342</td>\n",
       "      <td>-0.261077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106603</td>\n",
       "      <td>-0.137346</td>\n",
       "      <td>-0.124422</td>\n",
       "      <td>0.099997</td>\n",
       "      <td>0.049905</td>\n",
       "      <td>-0.067296</td>\n",
       "      <td>0.025073</td>\n",
       "      <td>0.048250</td>\n",
       "      <td>-0.014505</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7379</th>\n",
       "      <td>1.229626</td>\n",
       "      <td>0.949016</td>\n",
       "      <td>-0.062841</td>\n",
       "      <td>-1.722606</td>\n",
       "      <td>-1.057586</td>\n",
       "      <td>0.778410</td>\n",
       "      <td>-0.248871</td>\n",
       "      <td>0.273507</td>\n",
       "      <td>0.549379</td>\n",
       "      <td>1.051496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115777</td>\n",
       "      <td>-0.267204</td>\n",
       "      <td>-0.145887</td>\n",
       "      <td>0.055045</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>-0.048675</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>-0.005442</td>\n",
       "      <td>0.040276</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24479</th>\n",
       "      <td>0.340879</td>\n",
       "      <td>0.772770</td>\n",
       "      <td>-0.966337</td>\n",
       "      <td>-1.342151</td>\n",
       "      <td>-0.797795</td>\n",
       "      <td>0.009330</td>\n",
       "      <td>-0.323072</td>\n",
       "      <td>0.091520</td>\n",
       "      <td>0.804870</td>\n",
       "      <td>0.016989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171550</td>\n",
       "      <td>-0.138507</td>\n",
       "      <td>-0.049719</td>\n",
       "      <td>-0.004557</td>\n",
       "      <td>0.014382</td>\n",
       "      <td>-0.041696</td>\n",
       "      <td>-0.038541</td>\n",
       "      <td>-0.009300</td>\n",
       "      <td>0.079184</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19532</th>\n",
       "      <td>8.454393</td>\n",
       "      <td>0.867535</td>\n",
       "      <td>1.817414</td>\n",
       "      <td>1.123255</td>\n",
       "      <td>0.361935</td>\n",
       "      <td>1.035225</td>\n",
       "      <td>0.181511</td>\n",
       "      <td>0.224099</td>\n",
       "      <td>-0.080475</td>\n",
       "      <td>-0.045255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.648843</td>\n",
       "      <td>0.541824</td>\n",
       "      <td>-0.145423</td>\n",
       "      <td>0.128398</td>\n",
       "      <td>-0.384494</td>\n",
       "      <td>0.034080</td>\n",
       "      <td>-0.421518</td>\n",
       "      <td>0.158369</td>\n",
       "      <td>0.101909</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8695</th>\n",
       "      <td>0.512212</td>\n",
       "      <td>-1.893255</td>\n",
       "      <td>-1.413639</td>\n",
       "      <td>-0.895023</td>\n",
       "      <td>-0.016264</td>\n",
       "      <td>0.180163</td>\n",
       "      <td>-0.074641</td>\n",
       "      <td>-0.896404</td>\n",
       "      <td>0.101968</td>\n",
       "      <td>-0.400639</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.288649</td>\n",
       "      <td>-0.106217</td>\n",
       "      <td>-0.152433</td>\n",
       "      <td>-0.060046</td>\n",
       "      <td>-0.110437</td>\n",
       "      <td>-0.056551</td>\n",
       "      <td>0.009905</td>\n",
       "      <td>0.029002</td>\n",
       "      <td>-0.090838</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>0.239106</td>\n",
       "      <td>0.844269</td>\n",
       "      <td>-0.286306</td>\n",
       "      <td>-1.274410</td>\n",
       "      <td>1.260324</td>\n",
       "      <td>-0.665399</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.114577</td>\n",
       "      <td>0.809178</td>\n",
       "      <td>0.039943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366398</td>\n",
       "      <td>-0.415290</td>\n",
       "      <td>0.758599</td>\n",
       "      <td>-0.127784</td>\n",
       "      <td>-0.054578</td>\n",
       "      <td>-0.312127</td>\n",
       "      <td>-0.002217</td>\n",
       "      <td>-0.006963</td>\n",
       "      <td>0.106812</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8250</th>\n",
       "      <td>1.628326</td>\n",
       "      <td>-2.121414</td>\n",
       "      <td>1.124541</td>\n",
       "      <td>-0.151108</td>\n",
       "      <td>-0.128657</td>\n",
       "      <td>0.072585</td>\n",
       "      <td>-0.063428</td>\n",
       "      <td>-0.335233</td>\n",
       "      <td>0.055916</td>\n",
       "      <td>-0.155903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.414942</td>\n",
       "      <td>-0.074874</td>\n",
       "      <td>-0.270190</td>\n",
       "      <td>-0.033342</td>\n",
       "      <td>-0.304562</td>\n",
       "      <td>0.009105</td>\n",
       "      <td>-0.185370</td>\n",
       "      <td>0.018864</td>\n",
       "      <td>0.067465</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18511</th>\n",
       "      <td>-3.370279</td>\n",
       "      <td>-0.633653</td>\n",
       "      <td>2.278954</td>\n",
       "      <td>2.080791</td>\n",
       "      <td>-0.153023</td>\n",
       "      <td>-1.988961</td>\n",
       "      <td>-0.329479</td>\n",
       "      <td>-0.080015</td>\n",
       "      <td>-0.360904</td>\n",
       "      <td>-0.204693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203309</td>\n",
       "      <td>0.127252</td>\n",
       "      <td>0.264551</td>\n",
       "      <td>-0.026902</td>\n",
       "      <td>0.069529</td>\n",
       "      <td>0.515507</td>\n",
       "      <td>0.215882</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>-0.661055</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16074</th>\n",
       "      <td>2.293897</td>\n",
       "      <td>0.898854</td>\n",
       "      <td>-0.679156</td>\n",
       "      <td>-1.310976</td>\n",
       "      <td>-0.685169</td>\n",
       "      <td>0.143758</td>\n",
       "      <td>-0.203819</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>0.647041</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212200</td>\n",
       "      <td>-0.357577</td>\n",
       "      <td>-0.030663</td>\n",
       "      <td>0.080671</td>\n",
       "      <td>-0.078369</td>\n",
       "      <td>-0.079230</td>\n",
       "      <td>0.504632</td>\n",
       "      <td>-0.194059</td>\n",
       "      <td>0.060216</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15675 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       principal_feature_1  principal_feature_2  principal_feature_3  \\\n",
       "id                                                                     \n",
       "2103             -4.627833            -0.616020             1.011308   \n",
       "14649             1.426356            -1.070926            -0.445978   \n",
       "7379              1.229626             0.949016            -0.062841   \n",
       "24479             0.340879             0.772770            -0.966337   \n",
       "19532             8.454393             0.867535             1.817414   \n",
       "...                    ...                  ...                  ...   \n",
       "8695              0.512212            -1.893255            -1.413639   \n",
       "2192              0.239106             0.844269            -0.286306   \n",
       "8250              1.628326            -2.121414             1.124541   \n",
       "18511            -3.370279            -0.633653             2.278954   \n",
       "16074             2.293897             0.898854            -0.679156   \n",
       "\n",
       "       principal_feature_4  principal_feature_5  principal_feature_6  \\\n",
       "id                                                                     \n",
       "2103              1.157509            -0.969749             0.263241   \n",
       "14649            -2.012902            -0.774684            -0.178957   \n",
       "7379             -1.722606            -1.057586             0.778410   \n",
       "24479            -1.342151            -0.797795             0.009330   \n",
       "19532             1.123255             0.361935             1.035225   \n",
       "...                    ...                  ...                  ...   \n",
       "8695             -0.895023            -0.016264             0.180163   \n",
       "2192             -1.274410             1.260324            -0.665399   \n",
       "8250             -0.151108            -0.128657             0.072585   \n",
       "18511             2.080791            -0.153023            -1.988961   \n",
       "16074            -1.310976            -0.685169             0.143758   \n",
       "\n",
       "       principal_feature_7  principal_feature_8  principal_feature_9  \\\n",
       "id                                                                     \n",
       "2103              3.614747            -1.278219             1.025982   \n",
       "14649            -0.175381             0.390812            -0.219342   \n",
       "7379             -0.248871             0.273507             0.549379   \n",
       "24479            -0.323072             0.091520             0.804870   \n",
       "19532             0.181511             0.224099            -0.080475   \n",
       "...                    ...                  ...                  ...   \n",
       "8695             -0.074641            -0.896404             0.101968   \n",
       "2192              0.003516             0.114577             0.809178   \n",
       "8250             -0.063428            -0.335233             0.055916   \n",
       "18511            -0.329479            -0.080015            -0.360904   \n",
       "16074            -0.203819             0.297000             0.647041   \n",
       "\n",
       "       principal_feature_10  ...  principal_feature_22  principal_feature_23  \\\n",
       "id                           ...                                               \n",
       "2103              -0.205857  ...              0.037443             -0.181950   \n",
       "14649             -0.261077  ...             -0.106603             -0.137346   \n",
       "7379               1.051496  ...              0.115777             -0.267204   \n",
       "24479              0.016989  ...              0.171550             -0.138507   \n",
       "19532             -0.045255  ...              0.648843              0.541824   \n",
       "...                     ...  ...                   ...                   ...   \n",
       "8695              -0.400639  ...             -0.288649             -0.106217   \n",
       "2192               0.039943  ...              0.366398             -0.415290   \n",
       "8250              -0.155903  ...             -0.414942             -0.074874   \n",
       "18511             -0.204693  ...              0.203309              0.127252   \n",
       "16074              0.917722  ...              0.212200             -0.357577   \n",
       "\n",
       "       principal_feature_24  principal_feature_25  principal_feature_26  \\\n",
       "id                                                                        \n",
       "2103              -0.087537             -0.069821             -0.123980   \n",
       "14649             -0.124422              0.099997              0.049905   \n",
       "7379              -0.145887              0.055045              0.000938   \n",
       "24479             -0.049719             -0.004557              0.014382   \n",
       "19532             -0.145423              0.128398             -0.384494   \n",
       "...                     ...                   ...                   ...   \n",
       "8695              -0.152433             -0.060046             -0.110437   \n",
       "2192               0.758599             -0.127784             -0.054578   \n",
       "8250              -0.270190             -0.033342             -0.304562   \n",
       "18511              0.264551             -0.026902              0.069529   \n",
       "16074             -0.030663              0.080671             -0.078369   \n",
       "\n",
       "       principal_feature_27  principal_feature_28  principal_feature_29  \\\n",
       "id                                                                        \n",
       "2103              -0.054105             -0.005652             -0.010169   \n",
       "14649             -0.067296              0.025073              0.048250   \n",
       "7379              -0.048675              0.003114             -0.005442   \n",
       "24479             -0.041696             -0.038541             -0.009300   \n",
       "19532              0.034080             -0.421518              0.158369   \n",
       "...                     ...                   ...                   ...   \n",
       "8695              -0.056551              0.009905              0.029002   \n",
       "2192              -0.312127             -0.002217             -0.006963   \n",
       "8250               0.009105             -0.185370              0.018864   \n",
       "18511              0.515507              0.215882              0.028169   \n",
       "16074             -0.079230              0.504632             -0.194059   \n",
       "\n",
       "       principal_feature_30  label  \n",
       "id                                  \n",
       "2103               0.037983    1.0  \n",
       "14649             -0.014505    0.0  \n",
       "7379               0.040276    0.0  \n",
       "24479              0.079184    0.0  \n",
       "19532              0.101909    0.0  \n",
       "...                     ...    ...  \n",
       "8695              -0.090838    0.0  \n",
       "2192               0.106812    0.0  \n",
       "8250               0.067465    0.0  \n",
       "18511             -0.661055    1.0  \n",
       "16074              0.060216    0.0  \n",
       "\n",
       "[15675 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train= pandas.read_csv('../data/features.train.csv').set_index('id')\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e18757-9141-4ac1-b3c6-14b30c8d57dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=0.001, batch_size=32,\n",
       "              hidden_layer_sizes=(20, 10), learning_rate_init=0.1,\n",
       "              max_iter=1000, momentum=0.0, nesterovs_momentum=False,\n",
       "              random_state=0, solver=&#x27;sgd&#x27;, validation_fraction=0.0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=0.001, batch_size=32,\n",
       "              hidden_layer_sizes=(20, 10), learning_rate_init=0.1,\n",
       "              max_iter=1000, momentum=0.0, nesterovs_momentum=False,\n",
       "              random_state=0, solver=&#x27;sgd&#x27;, validation_fraction=0.0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.001, batch_size=32,\n",
       "              hidden_layer_sizes=(20, 10), learning_rate_init=0.1,\n",
       "              max_iter=1000, momentum=0.0, nesterovs_momentum=False,\n",
       "              random_state=0, solver='sgd', validation_fraction=0.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sklearn.neural_network.MLPClassifier(\n",
    "    hidden_layer_sizes    = (20, 10),\n",
    "    solver                = 'sgd', \n",
    "    activation            = 'logistic',\n",
    "    alpha                 = 0.001,\n",
    "    batch_size            = 32,\n",
    "    learning_rate         = 'constant',\n",
    "    learning_rate_init    = 0.1,\n",
    "    max_iter              = 1000,\n",
    "    momentum              = 0.0, \n",
    "    nesterovs_momentum    = False, \n",
    "    validation_fraction   = 0.0, \n",
    "    shuffle               = True,\n",
    "    random_state          = 0\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d663238-8529-4e48-9457-d54a8b0aa197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=0.001, batch_size=32,\n",
       "              hidden_layer_sizes=(20, 10), learning_rate_init=0.1,\n",
       "              max_iter=1000, momentum=0.0, nesterovs_momentum=False,\n",
       "              random_state=0, solver=&#x27;sgd&#x27;, validation_fraction=0.0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=0.001, batch_size=32,\n",
       "              hidden_layer_sizes=(20, 10), learning_rate_init=0.1,\n",
       "              max_iter=1000, momentum=0.0, nesterovs_momentum=False,\n",
       "              random_state=0, solver=&#x27;sgd&#x27;, validation_fraction=0.0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.001, batch_size=32,\n",
       "              hidden_layer_sizes=(20, 10), learning_rate_init=0.1,\n",
       "              max_iter=1000, momentum=0.0, nesterovs_momentum=False,\n",
       "              random_state=0, solver='sgd', validation_fraction=0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    data_train.drop(['label'], axis = 'columns'),\n",
    "    data_train['label']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adf65e6e-c152-4ec9-8eb2-d4f1ca1f4453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/model_with_regularization_and_more_than_2_layers.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model,'../model/model_with_regularization_and_more_than_2_layers.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "003be205-d24e-4a62-82d5-77cb3e5cd9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'logistic',\n",
       " 'alpha': 0.001,\n",
       " 'batch_size': 32,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (20, 10),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.1,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 1000,\n",
       " 'momentum': 0.0,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': False,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': 0,\n",
       " 'shuffle': True,\n",
       " 'solver': 'sgd',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.0,\n",
       " 'verbose': False,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f3d267e-0640-45da-9657-dc5fb34736e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../model/model_with_regularization_and_more_than_2_layers_config.json', 'w') as f:\n",
    "    json.dump(model.get_params(), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
