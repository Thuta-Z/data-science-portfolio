{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center>\n",
    "    <img src=\"https://itschool.mfu.ac.th/fileadmin/templatesItschool/assets/img/Header-School-IT-MFU_Eng.png\" width=\"400\" alt=\"cognitiveclass.ai logo\"  />\n",
    "</center>\n",
    "\n",
    "# 1501112: Individual Project # Classifying Cats & Dogs with Machine Learning (Dr.Surapol V.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As humans, it's easy to identify differences between two subjects. How does a machine tell them apart? One such way is through Support Vector Machines (SVM), a supervised learning model that analyzes data used for classification and regression tasks. In this lab, you'll learn to train SVM for classifying images of cats and dogs by extracting Histogram of Oriented Gradients (H.O.G.) features from the input. Notably, we can use the model on any new image that we upload!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## **Table of Contents**\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"https://#Objectives\">Objectives</a></li>\n",
    "    <li>\n",
    "        <a href=\"https://#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"https://#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n",
    "            <li><a href=\"https://#Importing-Required-Libraries\">Importing Required Libraries</a></li>\n",
    "            <li><a href=\"https://#Defining-Helper-Functions\">Defining Helper Functions</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "       <a href=\"https://#Download-Image-Annotations\">Download Image Annotations</a>\n",
    "    </li>\n",
    "    <li>\n",
    "       <a href=\"https://#Histogram-of-Oriented-Gradients-(H.O.G.)\">Histogram of Oriented Gradients (H.O.G.)</a>\n",
    "    </li>\n",
    "    <li>\n",
    "       <a href=\"https://#Load-Images-into-Train/Test-Sets\">Load Images into Train/Test Sets</a>\n",
    "    </li>\n",
    "    <li>\n",
    "       <a href=\"https://#Hyperparameter-Tuning\">Hyperparameter Tuning</a>\n",
    "    </li>\n",
    "    <li>\n",
    "       <a href=\"https://#Predict-New-Images\">Predict New Images</a>\n",
    "    </li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this guided project you will be able to:\n",
    "\n",
    "*   Extract H.O.G. features from images\n",
    "*   Train an SVM model on image inputs\n",
    "*   Tune hyperparameters with Grid Search and evaluate model performance\n",
    "*   Classify new images of cats and dogs with SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this guided project, we will be using the following libraries:\n",
    "\n",
    "*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n",
    "*   [`OpenCV`](https://docs.opencv.org/4.x/index.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for other image processing functions.\n",
    "*   [`scikit-learn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for machine learning and machine-learning-pipeline related functions.\n",
    "*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Installing Required Libraries\n",
    "\n",
    "The following required libraries are pre-installed in the Skills Network Labs environment. However, if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda), you will need to install these libraries by removing the `#` sign before `!pip` in the code cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n",
    "# !pip install -q pandas==1.3.3 numpy==1.21.2 ipywidgets==7.4.2 scipy tqdm==4.62.3 matplotlib==3.5.0 seaborn==0.9.0 scikit-image skillsnetwork==0.20.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import skillsnetwork\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Defining Helper Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load and process every image. Let's go over some concepts:\n",
    "\n",
    "<ul>\n",
    "        <ul>\n",
    "            <li><code>cv2.resize()</code> to resize the image </li>\n",
    "            <li><code>cv2.COLOR_BGR2GRAY()</code> will convert the images to greyscale image</li>\n",
    "            <li><code>hog()</code> will get the H.O.G. features from the image </li>\n",
    "        </ul>\n",
    "\n",
    "</ul>\n",
    "\n",
    "We will use this function to read and preprocess the images, the function will be explained in the **Histogram of Oriented Gradients (H.O.G.)** section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_paths):\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    # loop over the input images\n",
    "    for (i, image_path) in enumerate(image_paths):\n",
    "        # check if image has a provided label\n",
    "        if image_path[image_path.rfind(\"/\")+1:] in annotations[\"annotations\"]:\n",
    "            # read image\n",
    "            image = cv2.imread(image_path)\n",
    "            # convert image into an array\n",
    "            image = np.array(image).astype('uint8')\n",
    "            # resize the image\n",
    "            image = cv2.resize(image, (64, 64))\n",
    "            # convert it to grayscale\n",
    "            grey_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            # obtain hog features\n",
    "            hog_features, hog_images = hog(grey_image,\n",
    "                                  visualize=True,\n",
    "                                  block_norm='L2-Hys',\n",
    "                                  pixels_per_cell=(16, 16))\n",
    "            #label image using the annotations\n",
    "            label = class_object.index(annotations[\"annotations\"][image_path[image_path.rfind(\"/\")+1:]][0]['label'])\n",
    "            train_images.append(hog_features)\n",
    "            train_labels.append(label)\n",
    "    return train_images, train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Image Annotations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to download the images dataset that we'll be using. By default, the `skillsnetwork.prepare()` function will unzip the file and save it in the current working directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and unzip the images folder\n",
    "# Note: an error will appear if you run it more than once because the files will already have been downloaded\n",
    "await skillsnetwork.prepare(\"https://cv-studio-accessible.s3.us-south.cloud-object-storage.appdomain.cloud/cats_dogs_images_.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the folder exists in the current directory\n",
    "for path in Path(\".\").iterdir():\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll extract each image's file name and associated label from the annotations JSON file. We will later use this for creating the train and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotations JSON file containing file paths and image labels\n",
    "f = open('cats_dogs_images/_annotations.json')\n",
    "\n",
    "annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the format of the annotations we've just downloaded. The following code will display only the first 5 annotations. The annotations will come in a JSON file. What you can see is the image name as the key and dog as label object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_five = {k: annotations[\"annotations\"][k] for k in list(annotations[\"annotations\"])[:5]}\n",
    "first_five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Oriented Gradients (H.O.G.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H.O.G. stands for Histogram of Oriented Gradients. It uses the gradient orientation of the localized regions of an image and generates a histogram for each localized region. We will pick a random image and see how H.O.G. works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path of random image in the folder titled \"images\" of the current directory\n",
    "path = 'cats_dogs_images'\n",
    "sample_image = os.path.join(path, random.choice(list(annotations[\"annotations\"].keys())))\n",
    "sample_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create H.O.G. features, we will first convert the image to a grayscale image. Using the image path, we load it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = cv2.imread(sample_image)\n",
    "sample_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sample image\n",
    "plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dimension of the image\n",
    "sample_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize the image to a smaller size to allow the algorithm to run faster and convert the images to the grayscale to reduce the number of channels. `OpenCV` reads images as `BGR` so we will be using that color channel to convert to grayscale.\n",
    "\n",
    "Early developers at `OpenCV` chose `BGR` color format because it was the format that was popular among camera manufacturers and software providers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the sample image to take dimension 64x64\n",
    "sample_image = cv2.resize(sample_image, (64, 64))\n",
    "\n",
    "# Convert image from BGR to grayscale\n",
    "sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data to look at what it looks like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample_image, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run H.O.G. on the grayscale image to see what it will look like. We use a variation of L2-norm for normalization, and set cell size to 16x16. When we run H.O.G., it returns an array of features and the image/output it produced. The features are what we will use to train the SVM model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the features and image output from H.O.G.\n",
    "sample_image_features, sample_hog_image = hog(image=sample_image,\n",
    "                              visualize=True,\n",
    "                              block_norm='L2-Hys',\n",
    "                              pixels_per_cell=(16, 16))\n",
    "\n",
    "# Plot the H.O.G. image\n",
    "plt.imshow(sample_hog_image, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can see that the H.O.G. image identified some of the edges in the original image!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images into Train/Test Sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to apply H.O.G. to all images for SVM! First, let's load all the image paths and labels into separate lists using the function `load_images()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all the images' paths from directory 'images'\n",
    "image_paths = list(paths.list_images('cats_dogs_images'))\n",
    "\n",
    "# List for all unique class labels in the dataset\n",
    "class_object = annotations['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all images and labels from directory\n",
    "train_images, train_labels = load_images(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an array of the images so that the classifier can process it correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list into array\n",
    "train_array = np.array(train_images)\n",
    "print(train_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will <code>reshape</code> the array to <code>(total labels, 1)</code>. The array will look like this: <code>\\[\\[1], \\[0], ..., \\[0]]</code></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list into array\n",
    "labels_array = np.array(train_labels)\n",
    "\n",
    "# Make sure each entry is cast as integer and check array shape\n",
    "labels_array = labels_array.astype(int)\n",
    "print(labels_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape it so that it takes the appropriate dimension\n",
    "labels_array = labels_array.reshape((labels_array.size,1))\n",
    "print(labels_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the images and labels into a dataframe for better organization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for all the images and labels\n",
    "train_df = np.concatenate([train_array, labels_array], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the dataset into train and test sets for both features and responses (class labels).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how much % of the data should be used for training\n",
    "np.random.seed(0)\n",
    "percentage = 90\n",
    "partition = int(len(train_df)*percentage/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test using the partition\n",
    "x_train, x_test = train_df[:partition,:-1],  train_df[partition:,:-1]\n",
    "y_train, y_test = train_df[:partition,-1:].ravel(), train_df[partition:,-1:].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize performance for this classification task, we'll try out several combinations of hyperparameters to see which one yields the best results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel type to be used is a hyperparameter. The most common kernels are <code>RBF</code>, <code>poly</code>, or <code>sigmoid</code>. You can also create your own kernel.\n",
    "\n",
    "<code>C</code> behaves as a regularization parameter in the SVM. The <code>C</code> parameter trades off correct classification of the training examples against the maximization of the decision function’s margin. For larger values of <code>C</code>, a smaller margin will be accepted if the decision function is better at classifying all training points correctly. A lower <code>C</code> will encourage a larger margin, therefore a simpler decision function at the cost of accuracy. We select C and the best kernel by using the validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter values we want to try\n",
    "param_grid = {'kernel': ('linear', 'rbf', 'sigmoid'),'C': [1, 10, 50, 75, 100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>gamma</code> is a parameter of the RBF kernel and can be thought of as the spread of the kernel and, therefore, the decision region. Low values mean ‘far’ and high values mean ‘close’. The behaviour of the model is very sensitive to the gamma parameter. If gamma is too large, the radius of the area of influence of the support vectors only includes the support vector itself. Setting <code>gamma = 'scale'</code> uses 1 / (n_features \\* X.var()) as value of gamma. We create a Support Vector Classification object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base SVM model\n",
    "base_estimator = SVC(gamma='scale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the model and try different kernels and parameter values using the function <code>GridSearchCV</code>. The resulting output will be the model that performs best on the validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the start time of this tuning session\n",
    "start_datetime = datetime.now()\n",
    "start = time.time()\n",
    "\n",
    "# Perform Grid Search using the base model and the dictionary of hyperparameters\n",
    "svm = GridSearchCV(base_estimator, param_grid, cv=5)\n",
    "\n",
    "#Fit the data into the classifier\n",
    "svm.fit(x_train,y_train)\n",
    "\n",
    "#Get best hyperparameters from grid search\n",
    "best_parameters = svm.best_params_\n",
    "print(\"The best parameters are: {}\".format(best_parameters))\n",
    "print(\"----\")\n",
    "\n",
    "#Predict on the validation set\n",
    "y_pred = svm.predict(x_test)\n",
    "\n",
    "# Print accuracy score for the model on validation set\n",
    "print(\"Accuracy: \\n\"+str(accuracy_score(y_test, y_pred)))\n",
    "print(\"----\")\n",
    "\n",
    "# Record end time\n",
    "end = time.time()\n",
    "end_datetime = datetime.now()\n",
    "print(\"Total time spent for grid search: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predict New Images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use the best model from grid search for predicting new images! First, we will define a SVM model using the best hyperparameter combinations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the best performing model\n",
    "model = svm.best_estimator_\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define a helper function to use SVM for predicting the label of a new image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm(image):\n",
    "    # show the original image in RGB\n",
    "    orig_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(orig_image)\n",
    "    plt.show()\n",
    "    print('\\n')\n",
    "    \n",
    "    # convert the image into a numpy array\n",
    "    image = np.array(image).astype('uint8')\n",
    "    \n",
    "    # resize the image to a size of choice\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    \n",
    "    # convert to grayscale to reduce the information in the picture\n",
    "    grey_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # extract H.O.G features\n",
    "    hog_features, hog_image = hog(grey_image,\n",
    "                          visualize=True,\n",
    "                          block_norm='L2-Hys',\n",
    "                          pixels_per_cell=(16, 16))\n",
    "    \n",
    "    # convert the H.O.G features into a numpy array\n",
    "    image_array = np.array(hog_features)\n",
    "    \n",
    "    # reshape the array\n",
    "    image_array = image_array.reshape(1, -1)\n",
    "    \n",
    "    # make a label prediction\n",
    "    svm_pred = model.predict(image_array)\n",
    "    \n",
    "    # print the prediction\n",
    "    print('Your image was classified as a ' + str(annotations['labels'][int(svm_pred[0])]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, upload an image of your choice to see if the model is able to accurately predict whether the image has a dog or cat!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"your_uploaded_file\" with your file name\n",
    "my_image = cv2.imread(\"your_uploaded_file.jpg\")\n",
    "\n",
    "# Run the above function on the image to get a classification\n",
    "run_svm(my_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all code and save as \"Project_studentID.ipynb\" such that \"Project_5931501001.ipynb\" and upload to MFU-LMS assignment submission.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
